{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating additional space parameters to solve overfitting\n",
    "## Various iterations of the proccess of: cross validation->training->prediction on test are done below for various types of space parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.3 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from seaborn) (1.15.2)\n",
      "Requirement already satisfied: pandas>=0.15.2 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from seaborn) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2018.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.15.2->seaborn) (1.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\somasundaran\\miniconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install seaborn\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max Boosting = 1000 (change from 2k to 1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: K Folds Cross Validation using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/Somasundaran/Sanchita- Sales Prediction/\"\n",
    "submission_path= data_path+'submission/'\n",
    "fold_path = data_path+'fold_data/'\n",
    "\n",
    "from Functions import *\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline\n",
    "seed=1204\n",
    "\n",
    "cv_loss_list=[]\n",
    "n_iteration_list=[]\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    cv_losses=[]\n",
    "    cv_iteration=[]\n",
    "    for (train_idx,val_idx) in cv:\n",
    "        cv_train = X.iloc[train_idx]\n",
    "        cv_val = X.iloc[val_idx]\n",
    "        cv_y_train = y[train_idx]\n",
    "        cv_y_val = y[val_idx]\n",
    "        lgb_model = lgb.train(params, lgb.Dataset(cv_train, label=cv_y_train), 1000, \n",
    "                          lgb.Dataset(cv_val, label=cv_y_val), verbose_eval=False, \n",
    "                          early_stopping_rounds=100)\n",
    "       \n",
    "        train_pred = lgb_model.predict(cv_train,lgb_model.best_iteration+1)\n",
    "        val_pred = lgb_model.predict(cv_val,lgb_model.best_iteration+1)\n",
    "        \n",
    "        val_loss = root_mean_squared_error(cv_y_val,val_pred)\n",
    "        train_loss = root_mean_squared_error(cv_y_train,train_pred)\n",
    "        print('Train RMSE: {}. Val RMSE: {}'.format(train_loss,val_loss))\n",
    "        print('Best iteration: {}'.format(lgb_model.best_iteration))\n",
    "        cv_losses.append(val_loss)\n",
    "        cv_iteration.append(lgb_model.best_iteration)\n",
    "    print('6 fold results: {}'.format(cv_losses))\n",
    "    cv_loss_list.append(cv_losses)\n",
    "    n_iteration_list.append(cv_iteration)\n",
    "    \n",
    "    mean_cv_loss = np.mean(cv_losses)\n",
    "    print('Average iterations: {}'.format(np.mean(cv_iteration)))\n",
    "    print(\"Mean Cross Validation RMSE: {}\\n\".format(mean_cv_loss))\n",
    "    return {'loss': mean_cv_loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(space,seed=seed,max_evals=5):\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "        # trials=trials, \n",
    "        max_evals=max_evals)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_all_data(data_path,'new_sales_lag_after12.pickle')\n",
    "\n",
    "X,y = get_X_y(all_data,33)\n",
    "X.drop('date_block_num',axis=1,inplace=True)\n",
    "\n",
    "cv = get_cv_idxs(all_data,28,33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'colsample_bytree': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 128, \n",
    "               'subsample': 0.75, \n",
    "               'learning_rate': 0.05, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "               'num_leaves': 128,\n",
    "               'bagging_freq':1,\n",
    "               'seed':1204,\n",
    "    \n",
    "                'max_depth':10\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's rmse: 1.00189\n",
      "[20]\tvalid_0's rmse: 0.913893\n",
      "[30]\tvalid_0's rmse: 0.871634\n",
      "[40]\tvalid_0's rmse: 0.848812\n",
      "[50]\tvalid_0's rmse: 0.835027\n",
      "[60]\tvalid_0's rmse: 0.826329\n",
      "[70]\tvalid_0's rmse: 0.820018\n",
      "[80]\tvalid_0's rmse: 0.815058\n",
      "[90]\tvalid_0's rmse: 0.810961\n",
      "[100]\tvalid_0's rmse: 0.807412\n",
      "[110]\tvalid_0's rmse: 0.804104\n",
      "[120]\tvalid_0's rmse: 0.800666\n",
      "[130]\tvalid_0's rmse: 0.7979\n",
      "[140]\tvalid_0's rmse: 0.796012\n",
      "[150]\tvalid_0's rmse: 0.793724\n",
      "[160]\tvalid_0's rmse: 0.791076\n",
      "[170]\tvalid_0's rmse: 0.789228\n",
      "[180]\tvalid_0's rmse: 0.787496\n",
      "[190]\tvalid_0's rmse: 0.78564\n",
      "[200]\tvalid_0's rmse: 0.783352\n",
      "[210]\tvalid_0's rmse: 0.781588\n",
      "[220]\tvalid_0's rmse: 0.780076\n",
      "[230]\tvalid_0's rmse: 0.777793\n",
      "[240]\tvalid_0's rmse: 0.776475\n",
      "[250]\tvalid_0's rmse: 0.77534\n",
      "[260]\tvalid_0's rmse: 0.772513\n",
      "[270]\tvalid_0's rmse: 0.771484\n",
      "[280]\tvalid_0's rmse: 0.770399\n",
      "[290]\tvalid_0's rmse: 0.769121\n",
      "[300]\tvalid_0's rmse: 0.767691\n",
      "[310]\tvalid_0's rmse: 0.76633\n",
      "[320]\tvalid_0's rmse: 0.76559\n",
      "[330]\tvalid_0's rmse: 0.764047\n",
      "[340]\tvalid_0's rmse: 0.762834\n",
      "[350]\tvalid_0's rmse: 0.761782\n",
      "[360]\tvalid_0's rmse: 0.760446\n",
      "[370]\tvalid_0's rmse: 0.759466\n",
      "[380]\tvalid_0's rmse: 0.757923\n",
      "[390]\tvalid_0's rmse: 0.757024\n",
      "[400]\tvalid_0's rmse: 0.756376\n",
      "[410]\tvalid_0's rmse: 0.755673\n",
      "[420]\tvalid_0's rmse: 0.754671\n",
      "[430]\tvalid_0's rmse: 0.753354\n",
      "[440]\tvalid_0's rmse: 0.752518\n",
      "[450]\tvalid_0's rmse: 0.751443\n",
      "[460]\tvalid_0's rmse: 0.75091\n",
      "[470]\tvalid_0's rmse: 0.75015\n",
      "[480]\tvalid_0's rmse: 0.749554\n",
      "[490]\tvalid_0's rmse: 0.749091\n",
      "[500]\tvalid_0's rmse: 0.74841\n",
      "[510]\tvalid_0's rmse: 0.747877\n",
      "[520]\tvalid_0's rmse: 0.747234\n",
      "[530]\tvalid_0's rmse: 0.74667\n",
      "[540]\tvalid_0's rmse: 0.745648\n",
      "[550]\tvalid_0's rmse: 0.74517\n",
      "[560]\tvalid_0's rmse: 0.744242\n",
      "[570]\tvalid_0's rmse: 0.743647\n",
      "[580]\tvalid_0's rmse: 0.743012\n",
      "[590]\tvalid_0's rmse: 0.741857\n",
      "[600]\tvalid_0's rmse: 0.74141\n",
      "[610]\tvalid_0's rmse: 0.740909\n",
      "[620]\tvalid_0's rmse: 0.740515\n",
      "[630]\tvalid_0's rmse: 0.740014\n",
      "[640]\tvalid_0's rmse: 0.739341\n",
      "[650]\tvalid_0's rmse: 0.73902\n",
      "[660]\tvalid_0's rmse: 0.738599\n",
      "[670]\tvalid_0's rmse: 0.738059\n",
      "[680]\tvalid_0's rmse: 0.737426\n",
      "[690]\tvalid_0's rmse: 0.736962\n",
      "[700]\tvalid_0's rmse: 0.73638\n",
      "[710]\tvalid_0's rmse: 0.735971\n",
      "[720]\tvalid_0's rmse: 0.735561\n",
      "[730]\tvalid_0's rmse: 0.735212\n",
      "[740]\tvalid_0's rmse: 0.734847\n",
      "[750]\tvalid_0's rmse: 0.734571\n",
      "[760]\tvalid_0's rmse: 0.734022\n",
      "[770]\tvalid_0's rmse: 0.733611\n",
      "[780]\tvalid_0's rmse: 0.733226\n",
      "[790]\tvalid_0's rmse: 0.732771\n",
      "[800]\tvalid_0's rmse: 0.73225\n",
      "Wall time: 16min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 800, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lag = pd.read_csv(os.path.join(data_path, 'test_lag_data.csv'),encoding = \"ISO-8859-1\")\n",
    "test_lag.drop(['ID','item_name','date_block_num'],axis=1,inplace=True)\n",
    "test_lag_pred = lgb_model_full.predict(test_lag,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path =\"C:/Users/Somasundaran/Sanchita- Sales Prediction/\" ):\n",
    "    item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "    test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "    sub = test.copy()\n",
    "    sub['item_cnt_month'] = item_cnt_month\n",
    "    sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "    sub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "    return sub\n",
    "get_submission(test_lag_pred,'lightgbm_basic_6folds- Parameter tuning v1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tweaking the above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'colsample_bytree': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 128, \n",
    "               'subsample': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "               'num_leaves': 128,\n",
    "               'bagging_freq':1,\n",
    "               'seed':1204\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's rmse: 1.05698\n",
      "[20]\tvalid_0's rmse: 0.972714\n",
      "[30]\tvalid_0's rmse: 0.918783\n",
      "[40]\tvalid_0's rmse: 0.882679\n",
      "[50]\tvalid_0's rmse: 0.858197\n",
      "[60]\tvalid_0's rmse: 0.841073\n",
      "[70]\tvalid_0's rmse: 0.828324\n",
      "[80]\tvalid_0's rmse: 0.818616\n",
      "[90]\tvalid_0's rmse: 0.811198\n",
      "[100]\tvalid_0's rmse: 0.805408\n",
      "[110]\tvalid_0's rmse: 0.800574\n",
      "[120]\tvalid_0's rmse: 0.79646\n",
      "[130]\tvalid_0's rmse: 0.792662\n",
      "[140]\tvalid_0's rmse: 0.789279\n",
      "[150]\tvalid_0's rmse: 0.786108\n",
      "[160]\tvalid_0's rmse: 0.783363\n",
      "[170]\tvalid_0's rmse: 0.780447\n",
      "[180]\tvalid_0's rmse: 0.777746\n",
      "[190]\tvalid_0's rmse: 0.775659\n",
      "[200]\tvalid_0's rmse: 0.773514\n",
      "[210]\tvalid_0's rmse: 0.771435\n",
      "[220]\tvalid_0's rmse: 0.769754\n",
      "[230]\tvalid_0's rmse: 0.768097\n",
      "[240]\tvalid_0's rmse: 0.766674\n",
      "[250]\tvalid_0's rmse: 0.765152\n",
      "[260]\tvalid_0's rmse: 0.763868\n",
      "[270]\tvalid_0's rmse: 0.762353\n",
      "[280]\tvalid_0's rmse: 0.760885\n",
      "[290]\tvalid_0's rmse: 0.75949\n",
      "[300]\tvalid_0's rmse: 0.758241\n",
      "[310]\tvalid_0's rmse: 0.757211\n",
      "[320]\tvalid_0's rmse: 0.756147\n",
      "[330]\tvalid_0's rmse: 0.755176\n",
      "[340]\tvalid_0's rmse: 0.754028\n",
      "[350]\tvalid_0's rmse: 0.752854\n",
      "[360]\tvalid_0's rmse: 0.751938\n",
      "[370]\tvalid_0's rmse: 0.750874\n",
      "[380]\tvalid_0's rmse: 0.749928\n",
      "[390]\tvalid_0's rmse: 0.748905\n",
      "[400]\tvalid_0's rmse: 0.74812\n",
      "[410]\tvalid_0's rmse: 0.747309\n",
      "[420]\tvalid_0's rmse: 0.746378\n",
      "[430]\tvalid_0's rmse: 0.745504\n",
      "[440]\tvalid_0's rmse: 0.744268\n",
      "[450]\tvalid_0's rmse: 0.743388\n",
      "[460]\tvalid_0's rmse: 0.742732\n",
      "[470]\tvalid_0's rmse: 0.742047\n",
      "[480]\tvalid_0's rmse: 0.740763\n",
      "[490]\tvalid_0's rmse: 0.740046\n",
      "[500]\tvalid_0's rmse: 0.738739\n",
      "[510]\tvalid_0's rmse: 0.737956\n",
      "[520]\tvalid_0's rmse: 0.737334\n",
      "[530]\tvalid_0's rmse: 0.73674\n",
      "[540]\tvalid_0's rmse: 0.736038\n",
      "[550]\tvalid_0's rmse: 0.735214\n",
      "[560]\tvalid_0's rmse: 0.7346\n",
      "[570]\tvalid_0's rmse: 0.733822\n",
      "[580]\tvalid_0's rmse: 0.733178\n",
      "[590]\tvalid_0's rmse: 0.732353\n",
      "[600]\tvalid_0's rmse: 0.731712\n",
      "[610]\tvalid_0's rmse: 0.730858\n",
      "[620]\tvalid_0's rmse: 0.730313\n",
      "[630]\tvalid_0's rmse: 0.729696\n",
      "[640]\tvalid_0's rmse: 0.729074\n",
      "[650]\tvalid_0's rmse: 0.728539\n",
      "[660]\tvalid_0's rmse: 0.728024\n",
      "[670]\tvalid_0's rmse: 0.727462\n",
      "[680]\tvalid_0's rmse: 0.726921\n",
      "[690]\tvalid_0's rmse: 0.726391\n",
      "[700]\tvalid_0's rmse: 0.725873\n",
      "Wall time: 12min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 708, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path =\"C:/Users/Somasundaran/Sanchita- Sales Prediction/\" ):\n",
    "    item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "    test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "    sub = test.copy()\n",
    "    sub['item_cnt_month'] = item_cnt_month\n",
    "    sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "    sub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "    return sub\n",
    "get_submission(test_lag_pred,'lightgbm_basic_6folds- Parameter tuning v1.1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running hyperopt for different set of space parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth\n",
    "# L1 regularization\n",
    "# L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: \n",
      "{'colsample_bytree': 0.65, 'lambda_l1': 0.01, 'lambda_l2': 0.0001, 'learning_rate': 0.2, 'max_depth': 10, 'metric': 'rmse', 'min_data_in_leaf': 95, 'objective': 'regression', 'seed': 1204, 'subsample': 0.55}\n",
      "Train RMSE: 0.7816968520113593. Val RMSE: 0.8266133049486397\n",
      "Best iteration: 141\n",
      "Train RMSE: 0.8489706795981492. Val RMSE: 0.7789064230998629\n",
      "Best iteration: 23\n",
      "Train RMSE: 0.7485514005682771. Val RMSE: 0.7096606138852695\n",
      "Best iteration: 301\n",
      "Train RMSE: 0.7292370186092529. Val RMSE: 0.7695765839774419\n",
      "Best iteration: 437\n",
      "Train RMSE: 0.7676144186998185. Val RMSE: 0.8844194355914482\n",
      "Best iteration: 176\n",
      "Train RMSE: 0.8133357031504567. Val RMSE: 0.9341165627161099\n",
      "Best iteration: 52\n",
      "6 fold results: [0.8266133049486397, 0.7789064230998629, 0.7096606138852695, 0.7695765839774419, 0.8844194355914482, 0.9341165627161099]\n",
      "Average iterations: 188.33333333333334\n",
      "Mean Cross Validation RMSE: 0.8172154873697952\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.6000000000000001, 'lambda_l1': 10, 'lambda_l2': 0.1, 'learning_rate': 0.1, 'max_depth': 14, 'metric': 'rmse', 'min_data_in_leaf': 35, 'objective': 'regression', 'seed': 1204, 'subsample': 0.5}\n",
      "Train RMSE: 0.7530129094996697. Val RMSE: 0.834158032409504\n",
      "Best iteration: 439\n",
      "Train RMSE: 0.7762930735321812. Val RMSE: 0.76788140108388\n",
      "Best iteration: 265\n",
      "Train RMSE: 0.7207318976136277. Val RMSE: 0.7005203391436586\n",
      "Best iteration: 855\n",
      "Train RMSE: 0.7276849492376911. Val RMSE: 0.7695684702004564\n",
      "Best iteration: 683\n",
      "Train RMSE: 0.7893745231349222. Val RMSE: 0.8879416066509431\n",
      "Best iteration: 152\n",
      "Train RMSE: 0.7825850015334802. Val RMSE: 0.9185628258702118\n",
      "Best iteration: 205\n",
      "6 fold results: [0.834158032409504, 0.76788140108388, 0.7005203391436586, 0.7695684702004564, 0.8879416066509431, 0.9185628258702118]\n",
      "Average iterations: 433.1666666666667\n",
      "Mean Cross Validation RMSE: 0.813105445893109\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.5, 'lambda_l1': 0, 'lambda_l2': 0.0001, 'learning_rate': 0.15000000000000002, 'max_depth': 11, 'metric': 'rmse', 'min_data_in_leaf': 60, 'objective': 'regression', 'seed': 1204, 'subsample': 0.8500000000000001}\n",
      "Train RMSE: 0.7727038455803943. Val RMSE: 0.8318077052456534\n",
      "Best iteration: 231\n",
      "Train RMSE: 0.8099247970703204. Val RMSE: 0.7659914357972499\n",
      "Best iteration: 100\n",
      "Train RMSE: 0.7296755693363388. Val RMSE: 0.7040451010885981\n",
      "Best iteration: 603\n",
      "Train RMSE: 0.7245936047399325. Val RMSE: 0.7724829313663665\n",
      "Best iteration: 631\n",
      "Train RMSE: 0.7821548349349516. Val RMSE: 0.886746401399152\n",
      "Best iteration: 167\n",
      "Train RMSE: 0.814291873554858. Val RMSE: 0.9339356231390693\n",
      "Best iteration: 69\n",
      "6 fold results: [0.8318077052456534, 0.7659914357972499, 0.7040451010885981, 0.7724829313663665, 0.886746401399152, 0.9339356231390693]\n",
      "Average iterations: 300.1666666666667\n",
      "Mean Cross Validation RMSE: 0.8158348663393481\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.7000000000000001, 'lambda_l1': 0.01, 'lambda_l2': 0.0001, 'learning_rate': 0.45, 'max_depth': 9, 'metric': 'rmse', 'min_data_in_leaf': 70, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9500000000000001}\n",
      "Train RMSE: 0.7962781127498383. Val RMSE: 0.8593232307194463\n",
      "Best iteration: 54\n",
      "Train RMSE: 0.7926794371238962. Val RMSE: 0.7763189446778793\n",
      "Best iteration: 62\n",
      "Train RMSE: 0.7442740694535123. Val RMSE: 0.7195540652048401\n",
      "Best iteration: 170\n",
      "Train RMSE: 0.7631198846320173. Val RMSE: 0.782589531655229\n",
      "Best iteration: 108\n",
      "Train RMSE: 0.830652079284058. Val RMSE: 0.9131165410164208\n",
      "Best iteration: 16\n",
      "Train RMSE: 0.8536215137334056. Val RMSE: 0.9359134446726325\n",
      "Best iteration: 8\n",
      "6 fold results: [0.8593232307194463, 0.7763189446778793, 0.7195540652048401, 0.782589531655229, 0.9131165410164208, 0.9359134446726325]\n",
      "Average iterations: 69.66666666666667\n",
      "Mean Cross Validation RMSE: 0.8311359596577413\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.5, 'lambda_l1': 0.1, 'lambda_l2': 1, 'learning_rate': 0.5, 'max_depth': 12, 'metric': 'rmse', 'min_data_in_leaf': 65, 'objective': 'regression', 'seed': 1204, 'subsample': 0.6000000000000001}\n",
      "Train RMSE: 0.8783877467174284. Val RMSE: 0.8640086493061712\n",
      "Best iteration: 6\n",
      "Train RMSE: 0.8312791561669017. Val RMSE: 0.781704779325214\n",
      "Best iteration: 25\n",
      "Train RMSE: 0.8337870924863761. Val RMSE: 0.72559338175326\n",
      "Best iteration: 19\n",
      "Train RMSE: 0.7704803434873541. Val RMSE: 0.784544954598656\n",
      "Best iteration: 96\n",
      "Train RMSE: 0.8379317061843117. Val RMSE: 0.9079360228294063\n",
      "Best iteration: 15\n",
      "Train RMSE: 0.8224168667998986. Val RMSE: 0.9783513915665139\n",
      "Best iteration: 23\n",
      "6 fold results: [0.8640086493061712, 0.781704779325214, 0.72559338175326, 0.784544954598656, 0.9079360228294063, 0.9783513915665139]\n",
      "Average iterations: 30.666666666666668\n",
      "Mean Cross Validation RMSE: 0.8403565298965369\n",
      "\n",
      "The best hyperparameters are: \n",
      "{'colsample_bytree': 0.6000000000000001, 'lambda_l1': 5, 'lambda_l2': 3, 'learning_rate': 0.1, 'max_depth': 9, 'min_data_in_leaf': 3, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', np.arange(5, 15, dtype=int)),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "    'min_data_in_leaf': hp.choice('min_data_in_leaf',np.arange(20, 150,5, dtype=int)),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n",
    "    'seed':seed,\n",
    "    'objective': 'regression',\n",
    "    'metric':'rmse',\n",
    "    \n",
    "    'lambda_l1': hp.choice('lambda_l1',  [0, 0.0001, 0.01, 0.1, 1, 10]),\n",
    "    'lambda_l2': hp.choice('lambda_l2',  [0, 0.0001, 0.01, 0.1, 1, 10]),\n",
    "}\n",
    "best_hyperparams = optimize(space,max_evals=5)\n",
    "print(\"The best hyperparameters are: \")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'colsample_bytree': 0.6000000000000001,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 3, \n",
    "               'subsample': 0.5, \n",
    "               'learning_rate': 0.1, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "               'num_leaves': 128,\n",
    "               'bagging_freq':1,\n",
    "               'seed':1204,\n",
    "                'max_depth': 9,\n",
    "                'lambda_l1': 5, \n",
    "                'lambda_l2': 3\n",
    "    \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 0.784286\n",
      "[200]\tvalid_0's rmse: 0.75534\n",
      "[300]\tvalid_0's rmse: 0.737224\n",
      "[400]\tvalid_0's rmse: 0.722336\n",
      "[500]\tvalid_0's rmse: 0.709543\n",
      "[600]\tvalid_0's rmse: 0.698375\n",
      "[700]\tvalid_0's rmse: 0.690354\n",
      "[800]\tvalid_0's rmse: 0.681439\n",
      "Wall time: 12min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 800, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_lag = pd.read_csv(os.path.join(data_path, 'test_lag_data.csv'), encoding = \"ISO-8859-1\")\n",
    "test_lag.drop(['ID','item_name','date_block_num'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lag_pred = lgb_model_full.predict(test_lag,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path =\"C:/Users/Somasundaran/Sanchita- Sales Prediction/\" ):\n",
    "    item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "    test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "    sub = test.copy()\n",
    "    sub['item_cnt_month'] = item_cnt_month\n",
    "    sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "    sub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "    return sub\n",
    "get_submission(test_lag_pred,'lightgbm_basic_6folds- Parameter tuning v2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on revised test set (Including holiday features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'colsample_bytree': 0.6000000000000001,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 3, \n",
    "               'subsample': 0.5, \n",
    "               'learning_rate': 0.1, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "               'num_leaves': 128,\n",
    "               'bagging_freq':1,\n",
    "               'seed':1204,\n",
    "                'max_depth': 9,\n",
    "                'lambda_l1': 5, \n",
    "                'lambda_l2': 3\n",
    "    \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 0.784286\n",
      "[200]\tvalid_0's rmse: 0.75534\n",
      "[300]\tvalid_0's rmse: 0.737224\n",
      "[400]\tvalid_0's rmse: 0.722336\n",
      "[500]\tvalid_0's rmse: 0.709543\n",
      "[600]\tvalid_0's rmse: 0.698375\n",
      "[700]\tvalid_0's rmse: 0.690354\n",
      "[800]\tvalid_0's rmse: 0.681439\n",
      "Wall time: 12min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 800, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lag = pd.read_csv(os.path.join(data_path, 'test_lag_data_Holiday_features.csv'), encoding = \"ISO-8859-1\")\n",
    "test_lag.drop(['ID','item_name','date_block_num'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_block_target_mean</th>\n",
       "      <th>item_block_target_sum</th>\n",
       "      <th>item_cat_block_target_mean</th>\n",
       "      <th>item_cat_block_target_sum</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_block_target_mean</th>\n",
       "      <th>shop_block_target_sum</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>target</th>\n",
       "      <th>...</th>\n",
       "      <th>shop_block_target_mean_lag_12</th>\n",
       "      <th>shop_block_target_sum_lag_12</th>\n",
       "      <th>item_cat_block_target_mean_lag_12</th>\n",
       "      <th>item_cat_block_target_sum_lag_12</th>\n",
       "      <th>target_lag_12</th>\n",
       "      <th>Newyear_Xmas</th>\n",
       "      <th>Valentine_MenDay</th>\n",
       "      <th>WomenDay</th>\n",
       "      <th>Easter_Labor</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235043</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1.144403</td>\n",
       "      <td>6134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>5320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235043</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1.041406</td>\n",
       "      <td>9809.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235043</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1.144403</td>\n",
       "      <td>6134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>5232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235043</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1.099875</td>\n",
       "      <td>5275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>5268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235043</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>2.338131</td>\n",
       "      <td>12834.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_block_target_mean  item_block_target_sum  item_cat_block_target_mean  \\\n",
       "0                     0.0                    0.0                         0.0   \n",
       "1                     0.0                    0.0                         0.0   \n",
       "2                     0.0                    0.0                         0.0   \n",
       "3                     0.0                    0.0                         0.0   \n",
       "4                     0.0                    0.0                         0.0   \n",
       "\n",
       "   item_cat_block_target_sum  item_category_id  item_id  \\\n",
       "0                        0.0                19     5037   \n",
       "1                        0.0                55     5320   \n",
       "2                        0.0                19     5233   \n",
       "3                        0.0                23     5232   \n",
       "4                        0.0                20     5268   \n",
       "\n",
       "   shop_block_target_mean  shop_block_target_sum  shop_id  target    ...     \\\n",
       "0                     0.0                    0.0        5     0.0    ...      \n",
       "1                     0.0                    0.0        5     0.0    ...      \n",
       "2                     0.0                    0.0        5     0.0    ...      \n",
       "3                     0.0                    0.0        5     0.0    ...      \n",
       "4                     0.0                    0.0        5     0.0    ...      \n",
       "\n",
       "   shop_block_target_mean_lag_12  shop_block_target_sum_lag_12  \\\n",
       "0                       1.235043                        1445.0   \n",
       "1                       1.235043                        1445.0   \n",
       "2                       1.235043                        1445.0   \n",
       "3                       1.235043                        1445.0   \n",
       "4                       1.235043                        1445.0   \n",
       "\n",
       "   item_cat_block_target_mean_lag_12  item_cat_block_target_sum_lag_12  \\\n",
       "0                           1.144403                            6134.0   \n",
       "1                           1.041406                            9809.0   \n",
       "2                           1.144403                            6134.0   \n",
       "3                           1.099875                            5275.0   \n",
       "4                           2.338131                           12834.0   \n",
       "\n",
       "   target_lag_12  Newyear_Xmas  Valentine_MenDay  WomenDay  Easter_Labor  \\\n",
       "0            1.0             0                 0         0             0   \n",
       "1            0.0             0                 0         0             0   \n",
       "2            0.0             0                 0         0             0   \n",
       "3            0.0             0                 0         0             0   \n",
       "4            0.0             0                 0         0             0   \n",
       "\n",
       "   December  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lag_pred = lgb_model_full.predict(test_lag,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path =\"C:/Users/Somasundaran/Sanchita- Sales Prediction/\" ):\n",
    "    item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "    test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "    sub = test.copy()\n",
    "    sub['item_cnt_month'] = item_cnt_month\n",
    "    sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "    sub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "    return sub\n",
    "get_submission(test_lag_pred,'lightgbm_basic_6folds-Revised Test-Parameter tuning v1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Space Parameters- to combat overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: \n",
      "{'colsample_bytree': 0.8, 'lambda_l1': 0.01, 'lambda_l2': 0, 'learning_rate': 0.325, 'max_depth': 23, 'metric': 'rmse', 'min_data_in_leaf': 130, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9500000000000001}\n",
      "Train RMSE: 0.7921803749105867. Val RMSE: 0.8326647375713375\n",
      "Best iteration: 67\n",
      "Train RMSE: 0.7960730457120009. Val RMSE: 0.7654023603541752\n",
      "Best iteration: 62\n",
      "Train RMSE: 0.7386634079310335. Val RMSE: 0.710497573063942\n",
      "Best iteration: 236\n",
      "Train RMSE: 0.7604421244637175. Val RMSE: 0.7775750235172315\n",
      "Best iteration: 139\n",
      "Train RMSE: 0.7798507879899743. Val RMSE: 0.8851037539988987\n",
      "Best iteration: 78\n",
      "Train RMSE: 0.7875323848974793. Val RMSE: 0.9169401947469903\n",
      "Best iteration: 65\n",
      "6 fold results: [0.8326647375713375, 0.7654023603541752, 0.710497573063942, 0.7775750235172315, 0.8851037539988987, 0.9169401947469903]\n",
      "Average iterations: 107.83333333333333\n",
      "Mean Cross Validation RMSE: 0.8146972738754292\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.9, 'lambda_l1': 0, 'lambda_l2': 0.1, 'learning_rate': 0.42500000000000004, 'max_depth': 20, 'metric': 'rmse', 'min_data_in_leaf': 210, 'objective': 'regression', 'seed': 1204, 'subsample': 0.8}\n",
      "Train RMSE: 0.8600135560331762. Val RMSE: 0.8551886246761065\n",
      "Best iteration: 7\n",
      "Train RMSE: 0.8143208620792669. Val RMSE: 0.7802554496930603\n",
      "Best iteration: 31\n",
      "Train RMSE: 0.8556132107043446. Val RMSE: 0.7120046931356017\n",
      "Best iteration: 8\n",
      "Train RMSE: 0.7268106792964059. Val RMSE: 0.7749076362834892\n",
      "Best iteration: 249\n",
      "Train RMSE: 0.7538035960601361. Val RMSE: 0.8895705758093151\n",
      "Best iteration: 138\n",
      "Train RMSE: 0.8125279463943403. Val RMSE: 0.9099076195846147\n",
      "Best iteration: 27\n",
      "6 fold results: [0.8551886246761065, 0.7802554496930603, 0.7120046931356017, 0.7749076362834892, 0.8895705758093151, 0.9099076195846147]\n",
      "Average iterations: 76.66666666666667\n",
      "Mean Cross Validation RMSE: 0.8203057665303645\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.8500000000000001, 'lambda_l1': 0.1, 'lambda_l2': 0.01, 'learning_rate': 0.05, 'max_depth': 10, 'metric': 'rmse', 'min_data_in_leaf': 75, 'objective': 'regression', 'seed': 1204, 'subsample': 0.8500000000000001}\n",
      "Train RMSE: 0.7799029875910706. Val RMSE: 0.8363972759594153\n",
      "Best iteration: 537\n",
      "Train RMSE: 0.8056649663834927. Val RMSE: 0.7726383660529589\n",
      "Best iteration: 265\n",
      "Train RMSE: 0.7501282071727384. Val RMSE: 0.6945097164628038\n",
      "Best iteration: 996\n",
      "Train RMSE: 0.7476569562538892. Val RMSE: 0.7707220552288897\n",
      "Best iteration: 998\n",
      "Train RMSE: 0.7800658260145292. Val RMSE: 0.8817093975754149\n",
      "Best iteration: 451\n",
      "Train RMSE: 0.80941723657041. Val RMSE: 0.922788474303515\n",
      "Best iteration: 220\n",
      "6 fold results: [0.8363972759594153, 0.7726383660529589, 0.6945097164628038, 0.7707220552288897, 0.8817093975754149, 0.922788474303515]\n",
      "Average iterations: 577.8333333333334\n",
      "Mean Cross Validation RMSE: 0.8131275475971663\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.8500000000000001, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'learning_rate': 0.42500000000000004, 'max_depth': 18, 'metric': 'rmse', 'min_data_in_leaf': 85, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9500000000000001}\n",
      "Train RMSE: 0.7833069986925704. Val RMSE: 0.8480501174812303\n",
      "Best iteration: 57\n",
      "Train RMSE: 0.8686539256773211. Val RMSE: 0.7891896840813732\n",
      "Best iteration: 6\n",
      "Train RMSE: 0.774686476043748. Val RMSE: 0.7067283027850215\n",
      "Best iteration: 75\n",
      "Train RMSE: 0.7483718592816339. Val RMSE: 0.7847145910171645\n",
      "Best iteration: 134\n",
      "Train RMSE: 0.8247229473495009. Val RMSE: 0.9073052945708207\n",
      "Best iteration: 15\n",
      "Train RMSE: 0.8054680145026036. Val RMSE: 0.9248867269362174\n",
      "Best iteration: 33\n",
      "6 fold results: [0.8480501174812303, 0.7891896840813732, 0.7067283027850215, 0.7847145910171645, 0.9073052945708207, 0.9248867269362174]\n",
      "Average iterations: 53.333333333333336\n",
      "Mean Cross Validation RMSE: 0.8268124528119712\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.75, 'lambda_l1': 0.0001, 'lambda_l2': 0.01, 'learning_rate': 0.07500000000000001, 'max_depth': 15, 'metric': 'rmse', 'min_data_in_leaf': 95, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9500000000000001}\n",
      "Train RMSE: 0.7303218404754928. Val RMSE: 0.8316903024108188\n",
      "Best iteration: 1000\n",
      "Train RMSE: 0.7895892953236687. Val RMSE: 0.7693959974317861\n",
      "Best iteration: 248\n",
      "Train RMSE: 0.7319372273412238. Val RMSE: 0.6961911050846755\n",
      "Best iteration: 988\n",
      "Train RMSE: 0.7522422819381851. Val RMSE: 0.7693968883432437\n",
      "Best iteration: 566\n",
      "Train RMSE: 0.7700829900406013. Val RMSE: 0.8819633471857735\n",
      "Best iteration: 362\n",
      "Train RMSE: 0.7828807313903146. Val RMSE: 0.901336577702704\n",
      "Best iteration: 286\n",
      "6 fold results: [0.8316903024108188, 0.7693959974317861, 0.6961911050846755, 0.7693968883432437, 0.8819633471857735, 0.901336577702704]\n",
      "Average iterations: 575.0\n",
      "Mean Cross Validation RMSE: 0.8083290363598336\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.7000000000000001, 'lambda_l1': 0.1, 'lambda_l2': 0.0001, 'learning_rate': 0.42500000000000004, 'max_depth': 23, 'metric': 'rmse', 'min_data_in_leaf': 180, 'objective': 'regression', 'seed': 1204, 'subsample': 0.8}\n",
      "Train RMSE: 0.779856079820664. Val RMSE: 0.8396125792362327\n",
      "Best iteration: 86\n",
      "Train RMSE: 0.8541195813381267. Val RMSE: 0.7918390757109595\n",
      "Best iteration: 10\n",
      "Train RMSE: 0.7437818777277581. Val RMSE: 0.7054922231651172\n",
      "Best iteration: 207\n",
      "Train RMSE: 0.7663584936541598. Val RMSE: 0.7887894596482842\n",
      "Best iteration: 110\n",
      "Train RMSE: 0.8167076067529323. Val RMSE: 0.9031369420428377\n",
      "Best iteration: 25\n",
      "Train RMSE: 0.8593310593603709. Val RMSE: 0.9368977396034617\n",
      "Best iteration: 7\n",
      "6 fold results: [0.8396125792362327, 0.7918390757109595, 0.7054922231651172, 0.7887894596482842, 0.9031369420428377, 0.9368977396034617]\n",
      "Average iterations: 74.16666666666667\n",
      "Mean Cross Validation RMSE: 0.8276280032344822\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.65, 'lambda_l1': 0.01, 'lambda_l2': 0.1, 'learning_rate': 0.07500000000000001, 'max_depth': 20, 'metric': 'rmse', 'min_data_in_leaf': 220, 'objective': 'regression', 'seed': 1204, 'subsample': 0.7000000000000001}\n",
      "Train RMSE: 0.7813837440467303. Val RMSE: 0.8368078889689394\n",
      "Best iteration: 381\n",
      "Train RMSE: 0.7853697099986727. Val RMSE: 0.7660870412754955\n",
      "Best iteration: 324\n",
      "Train RMSE: 0.7767238497007183. Val RMSE: 0.7022595949200985\n",
      "Best iteration: 397\n",
      "Train RMSE: 0.750296150697584. Val RMSE: 0.7674944939360939\n",
      "Best iteration: 762\n",
      "Train RMSE: 0.7686925593608972. Val RMSE: 0.8783735829351128\n",
      "Best iteration: 456\n",
      "Train RMSE: 0.8201090127898137. Val RMSE: 0.9197649669626761\n",
      "Best iteration: 98\n",
      "6 fold results: [0.8368078889689394, 0.7660870412754955, 0.7022595949200985, 0.7674944939360939, 0.8783735829351128, 0.9197649669626761]\n",
      "Average iterations: 403.0\n",
      "Mean Cross Validation RMSE: 0.8117979281664027\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.65, 'lambda_l1': 0.1, 'lambda_l2': 0.0001, 'learning_rate': 0.05, 'max_depth': 22, 'metric': 'rmse', 'min_data_in_leaf': 230, 'objective': 'regression', 'seed': 1204, 'subsample': 0.7000000000000001}\n",
      "Train RMSE: 0.7628480733185986. Val RMSE: 0.8280923358837144\n",
      "Best iteration: 915\n",
      "Train RMSE: 0.7860017755464117. Val RMSE: 0.7670743260106533\n",
      "Best iteration: 500\n",
      "Train RMSE: 0.7696803955060885. Val RMSE: 0.6977528295507862\n",
      "Best iteration: 741\n",
      "Train RMSE: 0.7536506623505591. Val RMSE: 0.7640342345884318\n",
      "Best iteration: 1000\n",
      "Train RMSE: 0.7537629952593465. Val RMSE: 0.8740002611635073\n",
      "Best iteration: 1000\n",
      "Train RMSE: 0.7896887871959746. Val RMSE: 0.9129185334772845\n",
      "Best iteration: 391\n",
      "6 fold results: [0.8280923358837144, 0.7670743260106533, 0.6977528295507862, 0.7640342345884318, 0.8740002611635073, 0.9129185334772845]\n",
      "Average iterations: 757.8333333333334\n",
      "Mean Cross Validation RMSE: 0.807312086779063\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.8500000000000001, 'lambda_l1': 0.01, 'lambda_l2': 0.1, 'learning_rate': 0.2, 'max_depth': 14, 'metric': 'rmse', 'min_data_in_leaf': 150, 'objective': 'regression', 'seed': 1204, 'subsample': 0.7000000000000001}\n",
      "Train RMSE: 0.7489429145938886. Val RMSE: 0.8317319885200577\n",
      "Best iteration: 285\n",
      "Train RMSE: 0.8282319534979209. Val RMSE: 0.7773149387684525\n",
      "Best iteration: 39\n",
      "Train RMSE: 0.8368692204030509. Val RMSE: 0.7112955539544094\n",
      "Best iteration: 27\n",
      "Train RMSE: 0.7187575498199769. Val RMSE: 0.7722645478990114\n",
      "Best iteration: 504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.8039210640921063. Val RMSE: 0.886895916387914\n",
      "Best iteration: 63\n",
      "Train RMSE: 0.8542421990735928. Val RMSE: 0.9257487061867942\n",
      "Best iteration: 14\n",
      "6 fold results: [0.8317319885200577, 0.7773149387684525, 0.7112955539544094, 0.7722645478990114, 0.886895916387914, 0.9257487061867942]\n",
      "Average iterations: 155.33333333333334\n",
      "Mean Cross Validation RMSE: 0.8175419419527731\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.8, 'lambda_l1': 0.1, 'lambda_l2': 1, 'learning_rate': 0.125, 'max_depth': 21, 'metric': 'rmse', 'min_data_in_leaf': 110, 'objective': 'regression', 'seed': 1204, 'subsample': 0.7000000000000001}\n",
      "Train RMSE: 0.7610631480930864. Val RMSE: 0.832591594481484\n",
      "Best iteration: 322\n",
      "Train RMSE: 0.7630128558843561. Val RMSE: 0.7669208172631089\n",
      "Best iteration: 342\n",
      "Train RMSE: 0.7053852129517231. Val RMSE: 0.6971955198715297\n",
      "Best iteration: 993\n",
      "Train RMSE: 0.7247210603361951. Val RMSE: 0.7680042262716101\n",
      "Best iteration: 700\n",
      "Train RMSE: 0.7611515914659712. Val RMSE: 0.8890055265634437\n",
      "Best iteration: 281\n",
      "Train RMSE: 0.8402141229344469. Val RMSE: 0.9330221438586187\n",
      "Best iteration: 32\n",
      "6 fold results: [0.832591594481484, 0.7669208172631089, 0.6971955198715297, 0.7680042262716101, 0.8890055265634437, 0.9330221438586187]\n",
      "Average iterations: 445.0\n",
      "Mean Cross Validation RMSE: 0.8144566380516326\n",
      "\n",
      "The best hyperparameters are: \n",
      "{'colsample_bytree': 0.65, 'lambda_l1': 3, 'lambda_l2': 1, 'learning_rate': 0.05, 'max_depth': 12, 'min_data_in_leaf': 36, 'subsample': 0.7000000000000001}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', np.arange(5, 25, dtype=int)),\n",
    "    'subsample': hp.quniform('subsample', 0.6, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 1, 0.05),\n",
    "    'min_data_in_leaf': hp.choice('min_data_in_leaf',np.arange(50, 250,5, dtype=int)),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n",
    "    'seed':seed,\n",
    "    'objective': 'regression',\n",
    "    'metric':'rmse',\n",
    "    \n",
    "    'lambda_l1': hp.choice('lambda_l1',  [0, 0.0001, 0.01, 0.1, 1]),\n",
    "    'lambda_l2': hp.choice('lambda_l2',  [0, 0.0001, 0.01, 0.1, 1]),\n",
    "}\n",
    "best_hyperparams = optimize(space,max_evals=10)\n",
    "print(\"The best hyperparameters are: \")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'colsample_bytree': 0.65,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 36, \n",
    "               'subsample': 0.7000000000000001, \n",
    "               'learning_rate': 0.05, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "    \n",
    "               'num_leaves': 128,\n",
    "    \n",
    "               'bagging_freq':1,\n",
    "               'seed':1204,\n",
    "                'max_depth': 12,\n",
    "                'lambda_l1': 3, \n",
    "                'lambda_l2': 1\n",
    "    \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 0.791158\n",
      "[200]\tvalid_0's rmse: 0.762947\n",
      "[300]\tvalid_0's rmse: 0.745712\n",
      "[400]\tvalid_0's rmse: 0.733524\n",
      "[500]\tvalid_0's rmse: 0.72312\n",
      "[600]\tvalid_0's rmse: 0.714322\n",
      "[700]\tvalid_0's rmse: 0.704718\n",
      "[800]\tvalid_0's rmse: 0.698059\n",
      "[900]\tvalid_0's rmse: 0.691788\n",
      "[1000]\tvalid_0's rmse: 0.68611\n",
      "Wall time: 13min 50s\n",
      "Parser   : 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 1000, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lag_pred = lgb_model_full.predict(test_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path =\"C:/Users/Somasundaran/Sanchita- Sales Prediction/\" ):\n",
    "    item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "    test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "    sub = test.copy()\n",
    "    sub['item_cnt_month'] = item_cnt_month\n",
    "    sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "    sub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "    return sub\n",
    "get_submission(test_lag_pred,'lightgbm_basic_6folds- Parameter tuning v3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking the above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'colsample_bytree': 0.65,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 500, \n",
    "               'subsample': 0.7000000000000001, \n",
    "               'learning_rate': 0.05, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "    \n",
    "               'num_leaves': 256,\n",
    "    \n",
    "               'bagging_freq':1,\n",
    "               'seed':1204,\n",
    "                'max_depth': 12,\n",
    "                'lambda_l1': 3, \n",
    "                'lambda_l2': 1\n",
    "    \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 0.805414\n",
      "[200]\tvalid_0's rmse: 0.791468\n",
      "[300]\tvalid_0's rmse: 0.78076\n",
      "[400]\tvalid_0's rmse: 0.772698\n",
      "[500]\tvalid_0's rmse: 0.766313\n",
      "[600]\tvalid_0's rmse: 0.761188\n",
      "[700]\tvalid_0's rmse: 0.756788\n",
      "[800]\tvalid_0's rmse: 0.753099\n",
      "[900]\tvalid_0's rmse: 0.749767\n",
      "[1000]\tvalid_0's rmse: 0.746465\n",
      "Wall time: 22min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 1000, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lag_pred = lgb_model_full.predict(test_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path =\"C:/Users/Somasundaran/Sanchita- Sales Prediction/\" ):\n",
    "    item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "    test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "    sub = test.copy()\n",
    "    sub['item_cnt_month'] = item_cnt_month\n",
    "    sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "    sub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "    return sub\n",
    "get_submission(test_lag_pred,'lightgbm_basic_6folds- Parameter tuning v3.1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating maximum number of leaves + Change in space parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: \n",
      "{'colsample_bytree': 0.9, 'lambda_l1': 0, 'lambda_l2': 0.1, 'learning_rate': 0.07, 'max_depth': 9, 'metric': 'rmse', 'min_data_in_leaf': 80, 'num_leaves': 32, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9}\n",
      "Train RMSE: 0.759974846122296. Val RMSE: 0.8334317219916333\n",
      "Best iteration: 611\n",
      "Train RMSE: 0.8237353103591266. Val RMSE: 0.7754100590561498\n",
      "Best iteration: 133\n",
      "Train RMSE: 0.735915092319946. Val RMSE: 0.7024875837325822\n",
      "Best iteration: 991\n",
      "Train RMSE: 0.7363734525472706. Val RMSE: 0.7633673688177264\n",
      "Best iteration: 945\n",
      "Train RMSE: 0.8068807480595299. Val RMSE: 0.8864482861470799\n",
      "Best iteration: 169\n",
      "Train RMSE: 0.7817603803440171. Val RMSE: 0.9056419639185334\n",
      "Best iteration: 363\n",
      "6 fold results: [0.8334317219916333, 0.7754100590561498, 0.7024875837325822, 0.7633673688177264, 0.8864482861470799, 0.9056419639185334]\n",
      "Average iterations: 535.3333333333334\n",
      "Mean Cross Validation RMSE: 0.8111311639439508\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.8500000000000001, 'lambda_l1': 1, 'lambda_l2': 0.1, 'learning_rate': 0.03, 'max_depth': 7, 'metric': 'rmse', 'min_data_in_leaf': 265, 'num_leaves': 96, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9}\n",
      "Train RMSE: 0.7757825669979199. Val RMSE: 0.8290040253392463\n",
      "Best iteration: 936\n",
      "Train RMSE: 0.8331854950574625. Val RMSE: 0.7777896749450923\n",
      "Best iteration: 209\n",
      "Train RMSE: 0.7736547516835309. Val RMSE: 0.7015049936509486\n",
      "Best iteration: 996\n",
      "Train RMSE: 0.7701078110133912. Val RMSE: 0.7672417967079446\n",
      "Best iteration: 993\n",
      "Train RMSE: 0.7824882676191991. Val RMSE: 0.8809156042954743\n",
      "Best iteration: 683\n",
      "Train RMSE: 0.8505526754305117. Val RMSE: 0.9321939002419658\n",
      "Best iteration: 100\n",
      "6 fold results: [0.8290040253392463, 0.7777896749450923, 0.7015049936509486, 0.7672417967079446, 0.8809156042954743, 0.9321939002419658]\n",
      "Average iterations: 652.8333333333334\n",
      "Mean Cross Validation RMSE: 0.8147749991967786\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.8500000000000001, 'lambda_l1': 0.01, 'lambda_l2': 0.0001, 'learning_rate': 0.05, 'max_depth': 9, 'metric': 'rmse', 'min_data_in_leaf': 405, 'num_leaves': 64, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9}\n",
      "Train RMSE: 0.7628562500564458. Val RMSE: 0.8270257424166125\n",
      "Best iteration: 688\n",
      "Train RMSE: 0.8179029378066343. Val RMSE: 0.7758808198273982\n",
      "Best iteration: 163\n",
      "Train RMSE: 0.7460356368634825. Val RMSE: 0.6986313177041991\n",
      "Best iteration: 991\n",
      "Train RMSE: 0.7432369599770637. Val RMSE: 0.7669546468205344\n",
      "Best iteration: 990\n",
      "Train RMSE: 0.773146218619211. Val RMSE: 0.8808353865544359\n",
      "Best iteration: 474\n",
      "Train RMSE: 0.8054288216690426. Val RMSE: 0.9265238905253859\n",
      "Best iteration: 192\n",
      "6 fold results: [0.8270257424166125, 0.7758808198273982, 0.6986313177041991, 0.7669546468205344, 0.8808353865544359, 0.9265238905253859]\n",
      "Average iterations: 583.0\n",
      "Mean Cross Validation RMSE: 0.8126419673080942\n",
      "\n",
      "The best hyperparameters are: \n",
      "{'colsample_bytree': 0.9, 'lambda_l1': 0, 'lambda_l2': 3, 'learning_rate': 0.07, 'max_depth': 4, 'min_data_in_leaf': 6, 'num_leaves': 0, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', np.arange(5, 10, dtype=int)),\n",
    "    'subsample': hp.quniform('subsample', 0.6, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 1, 0.05),\n",
    "    'min_data_in_leaf': hp.choice('min_data_in_leaf',np.arange(50, 500,5, dtype=int)),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.01, 0.1, 0.01),\n",
    "    'seed':seed,\n",
    "    'objective': 'regression',\n",
    "    'metric':'rmse',\n",
    "    \n",
    "    'lambda_l1': hp.choice('lambda_l1',  [0, 0.0001, 0.01, 0.1, 1]),\n",
    "    'lambda_l2': hp.choice('lambda_l2',  [0, 0.0001, 0.01, 0.1, 1]),\n",
    "    \n",
    "    'num_leaves': hp.choice('num_leaves',np.arange(32, 129,32, dtype=int))\n",
    "}\n",
    "best_hyperparams = optimize(space,max_evals=3)\n",
    "print(\"The best hyperparameters are: \")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'colsample_bytree': 0.9, 'lambda_l1': 0, 'lambda_l2': 0.1, 'learning_rate': 0.07, 'max_depth': 9, 'metric': 'rmse', \n",
    "# 'min_data_in_leaf': 80, 'num_leaves': 32, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9\n",
    "                    \n",
    "lgb_params = {\n",
    "               'colsample_bytree': 0.9,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 80, \n",
    "               'subsample': 0.9, \n",
    "               'learning_rate': 0.07, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "               'num_leaves': 128,\n",
    "               'bagging_freq':1,\n",
    "               'seed':1204,\n",
    "                'max_depth': 9,\n",
    "                'lambda_l1': 0, \n",
    "                'lambda_l2': 0.1\n",
    "    \n",
    "              }                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 0.796542\n",
      "[200]\tvalid_0's rmse: 0.768223\n",
      "[300]\tvalid_0's rmse: 0.748677\n",
      "[400]\tvalid_0's rmse: 0.735852\n",
      "[500]\tvalid_0's rmse: 0.724154\n",
      "[600]\tvalid_0's rmse: 0.715332\n",
      "[700]\tvalid_0's rmse: 0.708109\n",
      "[800]\tvalid_0's rmse: 0.701862\n",
      "Wall time: 16min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 800, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lag = pd.read_csv(os.path.join(data_path, 'test_lag_data.csv'), encoding = \"ISO-8859-1\")\n",
    "test_lag.drop(['ID','item_name','date_block_num'],axis=1,inplace=True)\n",
    "test_lag_pred = lgb_model_full.predict(test_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(item_cnt_month,sub_name,clip=20,data_path =\"C:/Users/Somasundaran/Sanchita- Sales Prediction/\" ):\n",
    "    item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "    test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "    sub = test.copy()\n",
    "    sub['item_cnt_month'] = item_cnt_month\n",
    "    sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "    sub.to_csv(data_path+'submission/' + sub_name+'.csv',index=False)\n",
    "    return sub\n",
    "get_submission(test_lag_pred,'lightgbm_basic_6folds- Parameter tuning v4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
